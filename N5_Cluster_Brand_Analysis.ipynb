{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from folium.plugins import MarkerCluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 972174 entries, 0 to 972173\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   PUBLISH_DATE         972174 non-null  object \n",
      " 1   TRADING_NAME         972174 non-null  object \n",
      " 2   BRAND_DESCRIPTION    972174 non-null  object \n",
      " 3   PRODUCT_DESCRIPTION  972174 non-null  object \n",
      " 4   PRODUCT_PRICE        972174 non-null  float64\n",
      " 5   ADDRESS              972174 non-null  object \n",
      " 6   LOCATION             972174 non-null  object \n",
      " 7   POSTCODE             972174 non-null  int64  \n",
      " 8   AREA_DESCRIPTION     972174 non-null  object \n",
      " 9   REGION_DESCRIPTION   972174 non-null  object \n",
      " 10  latitude             972174 non-null  float64\n",
      " 11  longitude            972174 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(8)\n",
      "memory usage: 89.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the Final Datasets folder\n",
    "file_path = 'Final Datasets/N1_Cleaned_fueldata.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows and summary information\n",
    "data_info = data.info()\n",
    "data_head = data.head()\n",
    "\n",
    "data_info, data_head\n",
    "\n",
    "\n",
    "# Putting data into another variable\n",
    "data_cleaned = data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Analysis\n",
    "### \tHypothesis : More fuel stations in one area will  lead to higher fuel prices – Accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba6904754c74c26ae56b614a58c4fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Region:', options=('North of River', 'South of River', 'East/Hills'), value='Nort…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333a372c9b4b423c8d94253f15f59e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Year:', index=5, options=(2020, 2021, 2022, 2023, 2024, 'All Years'), value='All …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61005810965242e18bd45e6165a3f857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert 'PUBLISH_DATE' to datetime format\n",
    "data_cleaned['PUBLISH_DATE'] = pd.to_datetime(data_cleaned['PUBLISH_DATE'], errors='coerce')\n",
    "\n",
    "# Prepare the dropdown options for years (including 'All Years')\n",
    "years = sorted(data_cleaned['PUBLISH_DATE'].dt.year.unique().tolist())\n",
    "years.append('All Years')\n",
    "\n",
    "# Filter data based on 'AREA_DESCRIPTION' column\n",
    "north_data = data_cleaned[data_cleaned['AREA_DESCRIPTION'] == 'North of River']\n",
    "south_data = data_cleaned[data_cleaned['AREA_DESCRIPTION'] == 'South of River']\n",
    "east_data = data_cleaned[data_cleaned['AREA_DESCRIPTION'] == 'East/Hills']\n",
    "\n",
    "# Group data by latitude, longitude, and year\n",
    "north_location_prices = north_data.groupby(['latitude', 'longitude', north_data['PUBLISH_DATE'].dt.year])['PRODUCT_PRICE'].mean().reset_index()\n",
    "south_location_prices = south_data.groupby(['latitude', 'longitude', south_data['PUBLISH_DATE'].dt.year])['PRODUCT_PRICE'].mean().reset_index()\n",
    "east_location_prices = east_data.groupby(['latitude', 'longitude', east_data['PUBLISH_DATE'].dt.year])['PRODUCT_PRICE'].mean().reset_index()\n",
    "\n",
    "# Function to create clustering map for a region and year\n",
    "def generate_cluster_map(region, selected_year):\n",
    "    if region == 'North of River':\n",
    "        location_prices = north_location_prices\n",
    "    elif region == 'South of River':\n",
    "        location_prices = south_location_prices\n",
    "    else:\n",
    "        location_prices = east_location_prices\n",
    "    \n",
    "    # Filter data for the selected year or all years\n",
    "    if selected_year != 'All Years':\n",
    "        location_prices = location_prices[location_prices['PUBLISH_DATE'] == selected_year]\n",
    "        avg_price = location_prices['PRODUCT_PRICE'].mean()\n",
    "    else:\n",
    "        avg_price = location_prices['PRODUCT_PRICE'].mean()\n",
    "\n",
    "    # Create a map centered on Perth\n",
    "    region_map = folium.Map(location=[-31.9505, 115.8605], zoom_start=10)\n",
    "\n",
    "    # Add a marker cluster to group nearby stations\n",
    "    marker_cluster = MarkerCluster().add_to(region_map)\n",
    "\n",
    "    # Add markers to the cluster, colored by whether the station charges more than the regional average\n",
    "    for index, row in location_prices.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            popup=f\"Price: {row['PRODUCT_PRICE']} cents\",\n",
    "            icon=folium.Icon(color='red' if row['PRODUCT_PRICE'] > avg_price else 'green')\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "    # Save the map to an HTML file\n",
    "    region_safe = f\"Heat Map Data/{region}_heatmap_{selected_year}.html\"\n",
    "    region_map.save(region_safe)\n",
    "    \n",
    "    return region_map\n",
    "\n",
    "# Create dropdowns for region and year selection\n",
    "region_dropdown = widgets.Dropdown(\n",
    "    options=['North of River', 'South of River', 'East/Hills'],\n",
    "    value='North of River',\n",
    "    description='Select Region:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "year_dropdown = widgets.Dropdown(\n",
    "    options=years,\n",
    "    value='All Years',\n",
    "    description='Select Year:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Display the dropdowns\n",
    "display(region_dropdown)\n",
    "display(year_dropdown)\n",
    "\n",
    "# Display the map for the selected region and year\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define the callback function to update the map based on dropdown selection\n",
    "def update_cluster_map(change):\n",
    "    with output:\n",
    "        output.clear_output()  # Clear previous map\n",
    "        region_map = generate_cluster_map(region_dropdown.value, year_dropdown.value)\n",
    "        display(region_map)\n",
    "\n",
    "# Attach the callback to the dropdowns\n",
    "region_dropdown.observe(update_cluster_map, names='value')\n",
    "year_dropdown.observe(update_cluster_map, names='value')\n",
    "\n",
    "# Display the initial map\n",
    "with output:\n",
    "    display(generate_cluster_map('North of River', 'All Years'))\n",
    "\n",
    "display(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Map of Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'PUBLISH_DATE' to datetime format\n",
    "data_cleaned['PUBLISH_DATE'] = pd.to_datetime(data_cleaned['PUBLISH_DATE'], errors='coerce')\n",
    "\n",
    "# Prepare the dropdown options for years (including 'All Years')\n",
    "years = sorted(data_cleaned['PUBLISH_DATE'].dt.year.unique().tolist())\n",
    "years.append('All Years')\n",
    "\n",
    "# Filter data based on 'AREA_DESCRIPTION' column\n",
    "north_data = data_cleaned[data_cleaned['AREA_DESCRIPTION'] == 'North of River']\n",
    "south_data = data_cleaned[data_cleaned['AREA_DESCRIPTION'] == 'South of River']\n",
    "east_data = data_cleaned[data_cleaned['AREA_DESCRIPTION'] == 'East/Hills']\n",
    "\n",
    "# Group data by latitude, longitude, and year\n",
    "north_location_prices = north_data.groupby(['latitude', 'longitude', north_data['PUBLISH_DATE'].dt.year])['PRODUCT_PRICE'].mean().reset_index()\n",
    "south_location_prices = south_data.groupby(['latitude', 'longitude', south_data['PUBLISH_DATE'].dt.year])['PRODUCT_PRICE'].mean().reset_index()\n",
    "east_location_prices = east_data.groupby(['latitude', 'longitude', east_data['PUBLISH_DATE'].dt.year])['PRODUCT_PRICE'].mean().reset_index()\n",
    "\n",
    "# Function to generate heatmap for a region and year\n",
    "def generate_heatmap(region, selected_year):\n",
    "    if region == 'North of River':\n",
    "        location_prices = north_location_prices\n",
    "    elif region == 'South of River':\n",
    "        location_prices = south_location_prices\n",
    "    else:\n",
    "        location_prices = east_location_prices\n",
    "    \n",
    "    # Filter data for the selected year or use all years\n",
    "    if selected_year != 'All Years':\n",
    "        location_prices = location_prices[location_prices['PUBLISH_DATE'] == selected_year]\n",
    "\n",
    "    # Create a map centered on Perth\n",
    "    region_map = folium.Map(location=[-31.9505, 115.8605], zoom_start=10)\n",
    "\n",
    "    # Prepare data for heatmap\n",
    "    heat_data = [[row['latitude'], row['longitude']] for index, row in location_prices.iterrows()]\n",
    "\n",
    "    # Add heatmap layer\n",
    "    HeatMap(heat_data).add_to(region_map)\n",
    "\n",
    "    # Save the map to an HTML file\n",
    "    region_safe = f\"Heat Map Data/{region}_heatmap_{selected_year}.html\"\n",
    "    region_map.save(region_safe)\n",
    "\n",
    "    return region_map\n",
    "\n",
    "# Create dropdowns for region and year selection\n",
    "region_dropdown = widgets.Dropdown(\n",
    "    options=['North of River', 'South of River', 'East/Hills'],\n",
    "    value='North of River',\n",
    "    description='Select Region:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "year_dropdown = widgets.Dropdown(\n",
    "    options=years,\n",
    "    value='All Years',\n",
    "    description='Select Year:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Display the dropdowns\n",
    "display(region_dropdown)\n",
    "display(year_dropdown)\n",
    "\n",
    "# Display the heatmap for the selected region and year\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define the callback function to update the heatmap based on dropdown selection\n",
    "def update_heatmap(change):\n",
    "    with output:\n",
    "        output.clear_output()  # Clear previous map\n",
    "        region_map = generate_heatmap(region_dropdown.value, year_dropdown.value)\n",
    "        display(region_map)\n",
    "\n",
    "# Attach the callback to the dropdowns\n",
    "region_dropdown.observe(update_heatmap, names='value')\n",
    "year_dropdown.observe(update_heatmap, names='value')\n",
    "\n",
    "# Display the initial heatmap\n",
    "with output:\n",
    "    display(generate_heatmap('North of River', 'All Years'))\n",
    "\n",
    "display(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Station Density vs Price Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_38264\\1608946662.py:20: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  convex_hull = gdf.unary_union.convex_hull  # Create the convex hull around the points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact area of North of River: 1206.27 km²\n",
      "Exact area of South of River: 1422.59 km²\n",
      "Exact area of East/Hills: 1050.81 km²\n",
      "Correlation between station density and average price: 0.8637151251361079\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "\n",
    "# Convert latitude and longitude to a GeoDataFrame\n",
    "def create_geodataframe(region_data):\n",
    "    geometry = [Point(xy) for xy in zip(region_data['longitude'], region_data['latitude'])]\n",
    "    gdf = gpd.GeoDataFrame(region_data, geometry=geometry)\n",
    "\n",
    "    # Set the coordinate system to WGS84 (latitude/longitude)\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "    \n",
    "    # Convert to UTM for accurate area calculations (automatic zone detection)\n",
    "    gdf = gdf.to_crs(gdf.estimate_utm_crs())\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "# Calculate the area using the convex hull (in square kilometers)\n",
    "def calculate_region_area(gdf):\n",
    "    convex_hull = gdf.unary_union.convex_hull  # Create the convex hull around the points\n",
    "    area_sq_km = convex_hull.area / 1e6  # Convert area from square meters to square kilometers\n",
    "    return area_sq_km\n",
    "\n",
    "# Create GeoDataFrames for each region\n",
    "north_gdf = create_geodataframe(north_data)\n",
    "south_gdf = create_geodataframe(south_data)\n",
    "east_gdf = create_geodataframe(east_data)\n",
    "\n",
    "# Calculate the exact area for each region\n",
    "north_area = calculate_region_area(north_gdf)\n",
    "south_area = calculate_region_area(south_gdf)\n",
    "east_area = calculate_region_area(east_gdf)\n",
    "\n",
    "print(f\"Exact area of North of River: {north_area:.2f} km²\")\n",
    "print(f\"Exact area of South of River: {south_area:.2f} km²\")\n",
    "print(f\"Exact area of East/Hills: {east_area:.2f} km²\")\n",
    "\n",
    "# Now we can use these exact areas to calculate station density\n",
    "region_areas = {\n",
    "    'North of River': north_area,\n",
    "    'South of River': south_area,\n",
    "    'East/Hills': east_area\n",
    "}\n",
    "\n",
    "# Calculate station density (number of stations per square km) and average price for each region\n",
    "def calculate_density_and_avg_price(region_data, region_name):\n",
    "    num_stations = region_data[['latitude', 'longitude']].drop_duplicates().shape[0]\n",
    "    density = num_stations / region_areas[region_name]  # Stations per square kilometer\n",
    "    avg_price = region_data['PRODUCT_PRICE'].mean()\n",
    "    return density, avg_price\n",
    "\n",
    "# Calculate for each region\n",
    "north_density, north_avg_price = calculate_density_and_avg_price(north_data, 'North of River')\n",
    "south_density, south_avg_price = calculate_density_and_avg_price(south_data, 'South of River')\n",
    "east_density, east_avg_price = calculate_density_and_avg_price(east_data, 'East/Hills')\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "df_density_price = pd.DataFrame({\n",
    "    'Region': ['North of River', 'South of River', 'East/Hills'],\n",
    "    'Density': [north_density, south_density, east_density],\n",
    "    'Avg_Price': [north_avg_price, south_avg_price, east_avg_price]\n",
    "})\n",
    "\n",
    "# Calculate the correlation between density and average price\n",
    "correlation = df_density_price['Density'].corr(df_density_price['Avg_Price'])\n",
    "print(f\"Correlation between station density and average price: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive Correlation:\n",
    "\n",
    "A correlation close to 1 suggests that there is a strong relationship between higher station density and higher prices.\n",
    "This is counterintuitive to what many might expect, as more stations typically suggest competition, which should drive prices down. However, in this case, the data suggests the opposite: areas with more stations tend to have higher prices.\n",
    "\n",
    "\n",
    "Price Control: \n",
    "In regions with high fuel station density, stations might be clustering in high-demand areas where consumers are less price-sensitive, allowing them to keep prices higher despite more competition.\n",
    "\n",
    "High Traffic Areas: \n",
    "These regions might be more urban or have higher traffic, where demand remains high, regardless of how many stations there are. Consequently, stations may feel less pressure to lower prices.\n",
    "\n",
    "Operational Costs: \n",
    "Urban or dense areas might also have higher operational costs (e.g., rent, labor), which could be passed on to consumers in the form of higher fuel prices.\n",
    "Local Factors: There may be local regulations, taxes, or other constraints in more densely populated areas that contribute to higher prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-Density Avg Price: 162.24 cents per litre\n",
      "Low-Density Avg Price: 161.34 cents per litre\n",
      "T-statistic: 1.8012639448622718, P-value: 0.3226392597319173\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Assuming station density has already been calculated\n",
    "# Define a threshold for high-density vs low-density (e.g., based on median density)\n",
    "density_threshold = df_density_price['Density'].median()\n",
    "\n",
    "# Classify regions as high-density or low-density\n",
    "df_density_price['Density_Class'] = df_density_price['Density'].apply(lambda x: 'High-Density' if x > density_threshold else 'Low-Density')\n",
    "\n",
    "# Group data by density class and calculate average prices\n",
    "high_density_prices = df_density_price[df_density_price['Density_Class'] == 'High-Density']['Avg_Price']\n",
    "low_density_prices = df_density_price[df_density_price['Density_Class'] == 'Low-Density']['Avg_Price']\n",
    "\n",
    "# Calculate basic statistics\n",
    "high_density_mean = high_density_prices.mean()\n",
    "low_density_mean = low_density_prices.mean()\n",
    "\n",
    "print(f\"High-Density Avg Price: {high_density_mean:.2f} cents per litre\")\n",
    "print(f\"Low-Density Avg Price: {low_density_mean:.2f} cents per litre\")\n",
    "\n",
    "# Perform a t-test to check if the difference in prices is statistically significant\n",
    "t_stat, p_value = ttest_ind(high_density_prices, low_density_prices)\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yearly Price Dispersion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>AREA_DESCRIPTION</th>\n",
       "      <th>Price_Std_Dev</th>\n",
       "      <th>Avg_Price</th>\n",
       "      <th>Num_Stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>East/Hills</td>\n",
       "      <td>16.306107</td>\n",
       "      <td>118.432711</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>North of River</td>\n",
       "      <td>16.946110</td>\n",
       "      <td>119.486999</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>South of River</td>\n",
       "      <td>16.802103</td>\n",
       "      <td>118.965935</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>East/Hills</td>\n",
       "      <td>17.832225</td>\n",
       "      <td>145.129224</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>North of River</td>\n",
       "      <td>18.475315</td>\n",
       "      <td>146.037248</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021</td>\n",
       "      <td>South of River</td>\n",
       "      <td>18.326949</td>\n",
       "      <td>145.465984</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022</td>\n",
       "      <td>East/Hills</td>\n",
       "      <td>17.468233</td>\n",
       "      <td>180.375608</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022</td>\n",
       "      <td>North of River</td>\n",
       "      <td>17.838685</td>\n",
       "      <td>180.486285</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>South of River</td>\n",
       "      <td>17.887519</td>\n",
       "      <td>179.572958</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023</td>\n",
       "      <td>East/Hills</td>\n",
       "      <td>14.733387</td>\n",
       "      <td>183.402794</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023</td>\n",
       "      <td>North of River</td>\n",
       "      <td>15.806067</td>\n",
       "      <td>184.313313</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023</td>\n",
       "      <td>South of River</td>\n",
       "      <td>15.848742</td>\n",
       "      <td>183.536571</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024</td>\n",
       "      <td>East/Hills</td>\n",
       "      <td>14.125835</td>\n",
       "      <td>185.589724</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024</td>\n",
       "      <td>North of River</td>\n",
       "      <td>15.375380</td>\n",
       "      <td>186.257134</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024</td>\n",
       "      <td>South of River</td>\n",
       "      <td>15.364523</td>\n",
       "      <td>185.466500</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year AREA_DESCRIPTION  Price_Std_Dev   Avg_Price  Num_Stations\n",
       "0   2020       East/Hills      16.306107  118.432711            54\n",
       "1   2020   North of River      16.946110  119.486999           166\n",
       "2   2020   South of River      16.802103  118.965935           190\n",
       "3   2021       East/Hills      17.832225  145.129224            59\n",
       "4   2021   North of River      18.475315  146.037248           198\n",
       "5   2021   South of River      18.326949  145.465984           221\n",
       "6   2022       East/Hills      17.468233  180.375608            58\n",
       "7   2022   North of River      17.838685  180.486285           187\n",
       "8   2022   South of River      17.887519  179.572958           223\n",
       "9   2023       East/Hills      14.733387  183.402794            68\n",
       "10  2023   North of River      15.806067  184.313313           189\n",
       "11  2023   South of River      15.848742  183.536571           221\n",
       "12  2024       East/Hills      14.125835  185.589724            60\n",
       "13  2024   North of River      15.375380  186.257134           191\n",
       "14  2024   South of River      15.364523  185.466500           220"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Convert PUBLISH_DATE to datetime\n",
    "data_cleaned['PUBLISH_DATE'] = pd.to_datetime(data_cleaned['PUBLISH_DATE'])\n",
    "\n",
    "# Step 2: Group by area and year, then calculate the standard deviation of prices and count of stations\n",
    "price_variation_yearly = data_cleaned.groupby([data_cleaned['PUBLISH_DATE'].dt.year, 'AREA_DESCRIPTION']).agg({\n",
    "    'PRODUCT_PRICE': ['std', 'mean'],\n",
    "    'TRADING_NAME': 'nunique'  # Count unique stations by name\n",
    "}).reset_index()\n",
    "\n",
    "# Step 3: Rename columns for better readability\n",
    "price_variation_yearly.columns = ['Year', 'AREA_DESCRIPTION', 'Price_Std_Dev', 'Avg_Price', 'Num_Stations']\n",
    "\n",
    "# Step 4: Sort by number of stations\n",
    "price_variation_yearly = price_variation_yearly.sort_values('Year', ascending=True)\n",
    "\n",
    "# Step 5: Display the yearly data\n",
    "price_variation_yearly\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
