{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Uncleaned Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 972174 entries, 0 to 972173\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   PUBLISH_DATE         972174 non-null  object \n",
      " 1   TRADING_NAME         972174 non-null  object \n",
      " 2   BRAND_DESCRIPTION    972174 non-null  object \n",
      " 3   PRODUCT_DESCRIPTION  972174 non-null  object \n",
      " 4   PRODUCT_PRICE        972174 non-null  float64\n",
      " 5   ADDRESS              972174 non-null  object \n",
      " 6   LOCATION             972174 non-null  object \n",
      " 7   POSTCODE             972174 non-null  int64  \n",
      " 8   AREA_DESCRIPTION     972174 non-null  object \n",
      " 9   REGION_DESCRIPTION   972174 non-null  object \n",
      " 10  Unnamed: 10          0 non-null       float64\n",
      " 11  latitude             968780 non-null  float64\n",
      " 12  longitude            968780 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 96.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "   PUBLISH_DATE            TRADING_NAME BRAND_DESCRIPTION PRODUCT_DESCRIPTION  \\\n",
       " 0   01/01/2020          7-Eleven Ascot          7-Eleven                 ULP   \n",
       " 1   01/01/2020       7-Eleven Balcatta          7-Eleven                 ULP   \n",
       " 2   01/01/2020          7-Eleven Balga          7-Eleven                 ULP   \n",
       " 3   01/01/2020  7-Eleven Banksia Grove          7-Eleven                 ULP   \n",
       " 4   01/01/2020     7-Eleven Bassendean          7-Eleven                 ULP   \n",
       " \n",
       "    PRODUCT_PRICE                 ADDRESS       LOCATION  POSTCODE  \\\n",
       " 0          156.5   194 Great Eastern Hwy          ASCOT      6104   \n",
       " 1          153.9         174 Balcatta Rd       BALCATTA      6021   \n",
       " 2          157.5         102 Princess Rd          BALGA      6061   \n",
       " 3          157.5  1/300 Joseph Banks Bvd  BANKSIA GROVE      6031   \n",
       " 4          157.5      302-318 Collier Rd     BASSENDEAN      6054   \n",
       " \n",
       "   AREA_DESCRIPTION REGION_DESCRIPTION  Unnamed: 10   latitude   longitude  \n",
       " 0   South of River              Metro          NaN -31.941716  115.925018  \n",
       " 1   North of River              Metro          NaN -31.860374  115.809631  \n",
       " 2   North of River              Metro          NaN -31.856469  115.837493  \n",
       " 3   North of River              Metro          NaN -31.703315  115.803543  \n",
       " 4   North of River              Metro          NaN -31.906589  115.930147  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the Final Datasets folder\n",
    "file_path = 'Final Datasets/N1_Uncleaned_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows and summary information\n",
    "data_info = data.info()\n",
    "data_head = data.head()\n",
    "\n",
    "data_info, data_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(latitude     0\n",
       " longitude    0\n",
       " dtype: int64,\n",
       "   PUBLISH_DATE            TRADING_NAME BRAND_DESCRIPTION PRODUCT_DESCRIPTION  \\\n",
       " 0   2020-01-01          7-Eleven Ascot          7-Eleven                 ULP   \n",
       " 1   2020-01-01       7-Eleven Balcatta          7-Eleven                 ULP   \n",
       " 2   2020-01-01          7-Eleven Balga          7-Eleven                 ULP   \n",
       " 3   2020-01-01  7-Eleven Banksia Grove          7-Eleven                 ULP   \n",
       " 4   2020-01-01     7-Eleven Bassendean          7-Eleven                 ULP   \n",
       " \n",
       "    PRODUCT_PRICE                 ADDRESS       LOCATION  POSTCODE  \\\n",
       " 0          156.5   194 Great Eastern Hwy          ASCOT      6104   \n",
       " 1          153.9         174 Balcatta Rd       BALCATTA      6021   \n",
       " 2          157.5         102 Princess Rd          BALGA      6061   \n",
       " 3          157.5  1/300 Joseph Banks Bvd  BANKSIA GROVE      6031   \n",
       " 4          157.5      302-318 Collier Rd     BASSENDEAN      6054   \n",
       " \n",
       "   AREA_DESCRIPTION REGION_DESCRIPTION   latitude   longitude  \n",
       " 0   South of River              Metro -31.941716  115.925018  \n",
       " 1   North of River              Metro -31.860374  115.809631  \n",
       " 2   North of River              Metro -31.856469  115.837493  \n",
       " 3   North of River              Metro -31.703315  115.803543  \n",
       " 4   North of River              Metro -31.906589  115.930147  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the empty 'Unnamed: 10' column\n",
    "data_cleaned = data.drop(columns=['Unnamed: 10'])\n",
    "\n",
    "#Convert 'PUBLISH_DATE' to datetime format\n",
    "data_cleaned['PUBLISH_DATE'] = pd.to_datetime(data_cleaned['PUBLISH_DATE'], format='%d/%m/%Y')\n",
    "\n",
    "#Group by 'LOCATION' and calculate the mean latitude and longitude\n",
    "location_means = data_cleaned.groupby('LOCATION')[['latitude', 'longitude']].mean()\n",
    "\n",
    "#Impute missing values in 'latitude' and 'longitude' based on the 'LOCATION' means\n",
    "data_cleaned['latitude'] = data_cleaned.apply(\n",
    "    lambda row: location_means.loc[row['LOCATION'], 'latitude'] if pd.isna(row['latitude']) else row['latitude'], axis=1\n",
    ")\n",
    "data_cleaned['longitude'] = data_cleaned.apply(\n",
    "    lambda row: location_means.loc[row['LOCATION'], 'longitude'] if pd.isna(row['longitude']) else row['longitude'], axis=1\n",
    ")\n",
    "\n",
    "# Check if there are any remaining missing values after imputation\n",
    "missing_values_post_imputation = data_cleaned[['latitude', 'longitude']].isna().sum()\n",
    "\n",
    "missing_values_post_imputation.head(), data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers detected: 0\n"
     ]
    }
   ],
   "source": [
    "# Outlier Detection in PRODUCT_PRICE using Interquartile Range (IQR)\n",
    "Q1 = data_cleaned['PRODUCT_PRICE'].quantile(0.25)\n",
    "Q3 = data_cleaned['PRODUCT_PRICE'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Flag the outliers\n",
    "outliers = data_cleaned[(data_cleaned['PRODUCT_PRICE'] < lower_bound) | (data_cleaned['PRODUCT_PRICE'] > upper_bound)]\n",
    "print(f\"Number of outliers detected: {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Normalize text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned['TRADING_NAME'] = data_cleaned['TRADING_NAME'].str.lower().str.strip()\n",
    "data_cleaned['BRAND_DESCRIPTION'] = data_cleaned['BRAND_DESCRIPTION'].str.lower().str.strip()\n",
    "data_cleaned['REGION_DESCRIPTION'] = data_cleaned['REGION_DESCRIPTION'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in each column:\n",
      "PUBLISH_DATE           0\n",
      "TRADING_NAME           0\n",
      "BRAND_DESCRIPTION      0\n",
      "PRODUCT_DESCRIPTION    0\n",
      "PRODUCT_PRICE          0\n",
      "ADDRESS                0\n",
      "LOCATION               0\n",
      "POSTCODE               0\n",
      "AREA_DESCRIPTION       0\n",
      "REGION_DESCRIPTION     0\n",
      "latitude               0\n",
      "longitude              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = data_cleaned.isna().sum()\n",
    "print(\"Missing data in each column:\")\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Range Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned['PUBLISH_DATE'] = pd.to_datetime(data_cleaned['PUBLISH_DATE'], format='%d/%m/%Y', errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the min and max dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2020-01-01 00:00:00 to 2024-08-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "min_date = data_cleaned['PUBLISH_DATE'].min()\n",
    "max_date = data_cleaned['PUBLISH_DATE'].max()\n",
    "print(f\"Date range: {min_date} to {max_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate POSTCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid postcodes: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  PUBLISH_DATE            TRADING_NAME BRAND_DESCRIPTION PRODUCT_DESCRIPTION  \\\n",
       " 0   2020-01-01          7-eleven ascot          7-eleven                 ULP   \n",
       " 1   2020-01-01       7-eleven balcatta          7-eleven                 ULP   \n",
       " 2   2020-01-01          7-eleven balga          7-eleven                 ULP   \n",
       " 3   2020-01-01  7-eleven banksia grove          7-eleven                 ULP   \n",
       " 4   2020-01-01     7-eleven bassendean          7-eleven                 ULP   \n",
       " \n",
       "    PRODUCT_PRICE                 ADDRESS       LOCATION POSTCODE  \\\n",
       " 0          156.5   194 Great Eastern Hwy          ASCOT     6104   \n",
       " 1          153.9         174 Balcatta Rd       BALCATTA     6021   \n",
       " 2          157.5         102 Princess Rd          BALGA     6061   \n",
       " 3          157.5  1/300 Joseph Banks Bvd  BANKSIA GROVE     6031   \n",
       " 4          157.5      302-318 Collier Rd     BASSENDEAN     6054   \n",
       " \n",
       "   AREA_DESCRIPTION REGION_DESCRIPTION   latitude   longitude  \n",
       " 0   South of River              metro -31.941716  115.925018  \n",
       " 1   North of River              metro -31.860374  115.809631  \n",
       " 2   North of River              metro -31.856469  115.837493  \n",
       " 3   North of River              metro -31.703315  115.803543  \n",
       " 4   North of River              metro -31.906589  115.930147  ,\n",
       " Empty DataFrame\n",
       " Columns: [PUBLISH_DATE, TRADING_NAME, BRAND_DESCRIPTION, PRODUCT_DESCRIPTION, PRODUCT_PRICE, ADDRESS, LOCATION, POSTCODE, AREA_DESCRIPTION, REGION_DESCRIPTION, latitude, longitude]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [PUBLISH_DATE, TRADING_NAME, BRAND_DESCRIPTION, PRODUCT_DESCRIPTION, PRODUCT_PRICE, ADDRESS, LOCATION, POSTCODE, AREA_DESCRIPTION, REGION_DESCRIPTION, latitude, longitude]\n",
       " Index: [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that postcodes are valid (4-digit numbers)\n",
    "data_cleaned['POSTCODE'] = data_cleaned['POSTCODE'].astype(str).str.zfill(4)  # Ensure all postcodes have 4 digits\n",
    "invalid_postcodes = data_cleaned[~data_cleaned['POSTCODE'].str.match(r'^\\d{4}$')]\n",
    "\n",
    "print(f\"Number of invalid postcodes: {len(invalid_postcodes)}\")\n",
    "\n",
    "\n",
    "# Display the cleaned data and any detected issues\n",
    "data_cleaned.head(), outliers.head(), invalid_postcodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to Final Datasets/N1_Cleaned_fueldata.csv\n"
     ]
    }
   ],
   "source": [
    "# Export the cleaned data to a CSV file\n",
    "output_file_path = 'Final Datasets/N1_Cleaned_fueldata.csv'\n",
    "data_cleaned.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
